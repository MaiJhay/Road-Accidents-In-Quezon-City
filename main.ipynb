{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "import sys\n",
    "import time\n",
    "from sklearn import metrics\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from xgboost import XGBRegressor\n",
    "from xgboost import plot_importance\n",
    "from datetime import timedelta\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "color_pal = sns.color_palette()\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_month = pd.read_csv(\n",
    "    './data/Road Crash Statistics in Quezon City (2018-2022) - Classification by Month per case basis .csv', index_col=False)\n",
    "df_hour = pd.read_csv(\n",
    "    './data/Road Crash Statistics in Quezon City (2018-2022) - Classification by Time of Day.csv', index_col=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_month.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hour.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEPENDENT_VARIABLE = \"Grand Total\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_month[DEPENDENT_VARIABLE] = df_month[DEPENDENT_VARIABLE].fillna(0)\n",
    "df_month[DEPENDENT_VARIABLE] = df_month[DEPENDENT_VARIABLE].apply(\n",
    "    lambda x: 0 if x == 0 or x == '' or x == ' '\n",
    "    else float(\n",
    "        str(x).replace(',', '').replace('', ''))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hour[DEPENDENT_VARIABLE] = df_hour[DEPENDENT_VARIABLE].fillna(0)\n",
    "df_hour[DEPENDENT_VARIABLE] = df_hour[DEPENDENT_VARIABLE].apply(\n",
    "    lambda x: 0 if x == 0 or x == '' or x == ' '\n",
    "    else float(\n",
    "        str(x).replace(',', '').replace('', ''))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_month.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hour.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_month.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hour.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_month[DEPENDENT_VARIABLE].plot(style='-.',figsize=(15, 5))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hour[DEPENDENT_VARIABLE].plot(style='-.', figsize=(15, 5),)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_month[DEPENDENT_VARIABLE].plot(kind='hist', bins=100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hour[DEPENDENT_VARIABLE].plot(kind='hist', bins=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dateutil.relativedelta import relativedelta, MO\n",
    "dtime_day = {\n",
    "    \"00:00-00:59\": \"Night\",\n",
    "    \"01:00-01:59\": \"Night\",\n",
    "    \"02:00-02:59\": \"Night\",\n",
    "    \"03:00-03:59\": \"Night\",\n",
    "    \"04:00-04:59\": \"Night\",\n",
    "    \"05:00-05:59\": \"Morning\",\n",
    "    \"06:00-06:59\": \"Morning\",\n",
    "    \"07:00-07:59\": \"Morning\",\n",
    "    \"08:00-08:59\": \"Morning\",\n",
    "    \"09:00-09:59\": \"Morning\",\n",
    "    \"10:00-10:59\": \"Morning\",\n",
    "    \"11:00-11:59\": \"Morning\",\n",
    "    \"12:00-12:59\": \"Afternoon\",\n",
    "    \"13:00-13:59\": \"Afternoon\",\n",
    "    \"14:00-14:59\": \"Afternoon\",\n",
    "    \"15:00-15:59\": \"Afternoon\",\n",
    "    \"16:00-16:59\": \"Afternoon\",\n",
    "    \"17:00-17:59\": \"Afternoon\",\n",
    "    \"18:00-18:59\": \"Evening\",\n",
    "    \"19:00-19:59\": \"Evening\",\n",
    "    \"20:00-20:59\": \"Night\",\n",
    "    \"21:00-21:59\": \"Night\",\n",
    "    \"22:00-22:59\": \"Night\",\n",
    "    \"23:00-23:59\": \"Night\",\n",
    "    \"Time Not Stated\": \"unkown\",\n",
    "}\n",
    "\n",
    "# 0 - Not rush hour\n",
    "# 1 - Rush hour\n",
    "'''\n",
    "Worst traffic is at 7AM to 9AM and on 5PM to 9PM\n",
    "Medium traffic is at 9AM to 10AM and on 9PM to 11PM\n",
    "Low Traffic rest of the Hour\n",
    "'''\n",
    "rush_hour = {\n",
    "    \"00:00-00:59\":  \"Low\",\n",
    "    \"01:00-01:59\":  \"Low\",\n",
    "    \"02:00-02:59\": \"Low\",\n",
    "    \"03:00-03:59\": \"Low\",\n",
    "    \"04:00-04:59\": \"Low\",\n",
    "    \"05:00-05:59\": \"Low\",\n",
    "    \"06:00-06:59\": \"Low\",\n",
    "    \"07:00-07:59\": \"High\",\n",
    "    \"08:00-08:59\": \"High\",\n",
    "    \"09:00-09:59\": \"Medium\",\n",
    "    \"10:00-10:59\": \"Low\",\n",
    "    \"11:00-11:59\": \"Low\",\n",
    "    \"12:00-12:59\": \"Low\",\n",
    "    \"13:00-13:59\": \"Low\",\n",
    "    \"14:00-14:59\": \"Low\",\n",
    "    \"15:00-15:59\": \"Low\",\n",
    "    \"16:00-16:59\": \"Low\",\n",
    "    \"17:00-17:59\": \"High\",\n",
    "    \"18:00-18:59\": \"High\",\n",
    "    \"19:00-19:59\": \"High\",\n",
    "    \"20:00-20:59\": \"High\",\n",
    "    \"21:00-21:59\": \"Medium\",\n",
    "    \"22:00-22:59\": \"Medium\",\n",
    "    \"23:00-23:59\": \"Medium\",\n",
    "    \"Time Not Stated\": \"Neutral\",\n",
    "}\n",
    "\n",
    "\n",
    "def create_features_monthly(df, target_variable):\n",
    "    df['Year'] = df['Year'].apply(lambda x: int(x))\n",
    "    X = df[[\n",
    "        'Year', 'Month', DEPENDENT_VARIABLE\n",
    "    ]]\n",
    "    X = pd.get_dummies(X, columns=['Month'])\n",
    "    if target_variable:\n",
    "        y = df[target_variable]\n",
    "        return X, y\n",
    "    return X\n",
    "\n",
    "\n",
    "def create_features_hourly(df, target_variable):\n",
    "    def hourmin_decimal(time, index):\n",
    "        if time == 'Time Not Stated':\n",
    "            return -1\n",
    "        time = time.split('-')[index].split(':')\n",
    "        hour = int(time[0])\n",
    "        minutes = int(time[-1])\n",
    "        return int(hour) * 3600 + int(minutes) * 60\n",
    "\n",
    "    df['Year'] = df['Year'].apply(lambda x: int(x))\n",
    "    df['Day Time'] = df['Time Hour'].apply(lambda x:  dtime_day[x])\n",
    "    df['Hour Start'] = df['Time Hour'].apply(lambda x: hourmin_decimal(x, 0))\n",
    "    df['Hour End'] = df['Time Hour'].apply(lambda x: hourmin_decimal(x, -1))\n",
    "    df['Traffic'] = df['Time Hour'].apply(lambda x: rush_hour[x])\n",
    "    X = df[[\n",
    "        'Year', 'Day Time', 'Hour Start', 'Hour End', 'Traffic', DEPENDENT_VARIABLE\n",
    "    ]]\n",
    "    X = pd.get_dummies(X, columns=['Day Time', 'Traffic'])\n",
    "    if target_variable:\n",
    "        y = df[target_variable]\n",
    "        return X, y\n",
    "    return X\n",
    "\n",
    "\n",
    "def mean_absolute_percentage_error_func(y_true, y_pred):\n",
    "    '''\n",
    "    Calculate the mean absolute percentage error as a metric for evaluation\n",
    "    \n",
    "    Args:\n",
    "        y_true (float64): Y values for the dependent variable (test part), numpy array of floats \n",
    "        y_pred (float64): Predicted values for the dependen variable (test parrt), numpy array of floats\n",
    "    \n",
    "    Returns:\n",
    "        Mean absolute percentage error \n",
    "    '''\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    mape = np.mean(np.abs((y_true - y_pred) / y_true))\n",
    "    return mape\n",
    "\n",
    "\n",
    "def timeseries_evaluation_metrics_func(y_true, y_pred):\n",
    "    '''\n",
    "    Calculate the following evaluation metrics:\n",
    "        - MSE\n",
    "        - MAE\n",
    "        - RMSE\n",
    "        - MAPE\n",
    "        - R²\n",
    "    \n",
    "    Args:\n",
    "        y_true (float64): Y values for the dependent variable (test part), numpy array of floats \n",
    "        y_pred (float64): Predicted values for the dependen variable (test parrt), numpy array of floats\n",
    "    \n",
    "    Returns:\n",
    "        MSE, MAE, RMSE, MAPE and R² \n",
    "    '''\n",
    "    # print('Evaluation metric results: ')\n",
    "    mse = metrics.mean_squared_error(y_true, y_pred)\n",
    "    mae = metrics.mean_absolute_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(metrics.mean_squared_error(y_true, y_pred))\n",
    "    mape = mean_absolute_percentage_error_func(y_true, y_pred)\n",
    "    r2 = metrics.r2_score(y_true, y_pred)\n",
    "    return {\"mse\": mse, \"mae\": mae, \"rmse\": rmse, \"mape\": mape, \"r2\": r2}, [mse, mae, rmse, mape, r2 ]\n",
    "\n",
    "\n",
    "def dataframe_splitter(arr, indexes_range):\n",
    "    result = [[] for i in range(indexes_range)]\n",
    "    for i in range(indexes_range):\n",
    "        result[i] = [j[i] for j in arr]\n",
    "    return result\n",
    "\n",
    "\n",
    "def time_series_split(data_frame, target_column_name, n_splits=5):\n",
    "    X = data_frame.drop(target_column_name, axis=1)\n",
    "    y = data_frame[target_column_name]\n",
    "\n",
    "    tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "    train_test_sets = []\n",
    "\n",
    "    for train_index, test_index in tscv.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        train_test_sets.append((X_train, y_train, X_test, y_test))\n",
    "\n",
    "    return train_test_sets\n",
    "\n",
    "\n",
    "def print_values_metrics(model_name, metric_dict):\n",
    "  printed_metrics = ''.join(\n",
    "      [f' ({i}: {round(metric_dict[i], 2):,})\\t' for i in metric_dict])\n",
    "  print(f\"{printed_metrics}: {model_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------- Hour -----------\n",
    "df_hour_X = df_hour.copy()\n",
    "# Create hourly features\n",
    "df_hour_feature = create_features_hourly(df_hour_X, target_variable='')\n",
    "train_test_hour = time_series_split(df_hour_feature, DEPENDENT_VARIABLE, 2)\n",
    "\n",
    "# ----------- Monthly -----------\n",
    "df_month_X = df_month.copy()\n",
    "# Create monthly features\n",
    "df_month_feature = create_features_monthly(df_month_X, target_variable='')\n",
    "train_test_month = time_series_split(df_month_feature, DEPENDENT_VARIABLE, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import (LinearRegression, Ridge, Lasso, ElasticNet, BayesianRidge,\n",
    "                                  OrthogonalMatchingPursuit, ARDRegression, LogisticRegression,\n",
    "                                  PoissonRegressor, GammaRegressor, TweedieRegressor, PassiveAggressiveRegressor,\n",
    "                                  RANSACRegressor, TheilSenRegressor, HuberRegressor)\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.svm import (SVR, NuSVR, LinearSVR)\n",
    "from sklearn.tree import (DecisionTreeRegressor)\n",
    "from sklearn.ensemble import (ExtraTreesRegressor, AdaBoostRegressor,\n",
    "                              GradientBoostingRegressor, HistGradientBoostingRegressor, RandomForestRegressor)\n",
    "from sklearn.neighbors import (RadiusNeighborsRegressor)\n",
    "from sklearn.neural_network import (MLPRegressor)\n",
    "from sklearn.gaussian_process import (GaussianProcessRegressor)\n",
    "from xgboost import XGBRegressor, XGBRFRegressor\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.tsa.vector_ar.var_model import VAR\n",
    "from statsmodels.tsa.statespace.varmax import VARMAX\n",
    "\n",
    "include_params = True\n",
    "\n",
    "def linear_regression(trainX, trainY, testX):\n",
    "    param_grid = {\n",
    "        'fit_intercept': [True, False],\n",
    "    }\n",
    "    model = LinearRegression()\n",
    "    model = GridSearchCV(model, param_grid if include_params else {}, cv=3)\n",
    "    model.fit(trainX, trainY)\n",
    "\n",
    "    # Get the best model from the GridSearchCV object\n",
    "    best_model_hour = model.best_estimator_\n",
    "    predicted_results_hour = best_model_hour.predict(testX)\n",
    "    return predicted_results_hour\n",
    "def ridge(trainX, trainY, testX):\n",
    "    param_grid = {\n",
    "        'alpha': [1, 0.1, 0.01, 0.001, 0.0001, 0], \n",
    "        \"fit_intercept\": [True, False], \n",
    "        \"solver\": ['svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga']\n",
    "    }\n",
    "    model = Ridge()\n",
    "    model = GridSearchCV(model, param_grid if include_params else {}, cv=3)\n",
    "    model.fit(trainX, trainY)\n",
    "\n",
    "    # Get the best model from the GridSearchCV object\n",
    "    best_model_hour = model.best_estimator_\n",
    "    predicted_results_hour = best_model_hour.predict(testX)\n",
    "    return predicted_results_hour\n",
    "def lasso(trainX, trainY, testX):\n",
    "    param_grid = {\n",
    "        'alpha': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "        'fit_intercept': [True, False],\n",
    "        'max_iter': [500, 1000, 2000, 5000],\n",
    "        'tol': [1e-5, 1e-4, 1e-3],\n",
    "        'warm_start': [True, False],\n",
    "        'positive': [True, False],\n",
    "        'selection': ['cyclic', 'random']\n",
    "    }\n",
    "    model = Lasso()\n",
    "    model = GridSearchCV(model, param_grid if include_params else {}, cv=3)\n",
    "    model.fit(trainX, trainY)\n",
    "\n",
    "    # Get the best model from the GridSearchCV object\n",
    "    best_model_hour = model.best_estimator_\n",
    "    predicted_results_hour = best_model_hour.predict(testX)\n",
    "    return predicted_results_hour\n",
    "def elastic_net(trainX, trainY, testX):\n",
    "    param_grid = {\n",
    "        'alpha': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "        'l1_ratio': [0.1, 0.3, 0.5, 0.7, 0.9],\n",
    "        'fit_intercept': [True, False],\n",
    "        'max_iter': [500, 1000, 2000, 5000],\n",
    "        'tol': [1e-5, 1e-4, 1e-3],\n",
    "        'warm_start': [True, False],\n",
    "        'positive': [True, False],\n",
    "        'selection': ['cyclic', 'random']\n",
    "    }\n",
    "    model = ElasticNet()\n",
    "    model = GridSearchCV(model, param_grid if include_params else {}, cv=3)\n",
    "    model.fit(trainX, trainY)\n",
    "\n",
    "    # Get the best model from the GridSearchCV object\n",
    "    best_model_hour = model.best_estimator_\n",
    "    predicted_results_hour = best_model_hour.predict(testX)\n",
    "    return predicted_results_hour\n",
    "def bayesian_ridge(trainX, trainY, testX):\n",
    "    param_grid = {\n",
    "        'alpha_1': [1e-6, 1e-5, 1e-4, 1e-3],\n",
    "        'alpha_2': [1e-6, 1e-5, 1e-4, 1e-3],\n",
    "        'lambda_1': [1e-6, 1e-5, 1e-4, 1e-3],\n",
    "        'lambda_2': [1e-6, 1e-5, 1e-4, 1e-3],\n",
    "        'fit_intercept': [True, False],\n",
    "        'tol': [1e-5, 1e-4, 1e-3]\n",
    "    }\n",
    "    model = BayesianRidge()\n",
    "    model = GridSearchCV(model,  param_grid if include_params else {}, cv=3)\n",
    "    model.fit(trainX, trainY)\n",
    "\n",
    "    # Get the best model from the GridSearchCV object\n",
    "    best_model_hour = model.best_estimator_\n",
    "    predicted_results_hour = best_model_hour.predict(testX)\n",
    "    return predicted_results_hour\n",
    "def orthogonal_matching_pursuit(trainX, trainY, testX):\n",
    "    param_grid = {\n",
    "        'n_nonzero_coefs': list(range(1, trainX.shape[1] + 1)),\n",
    "        'fit_intercept': [True, False]\n",
    "    }\n",
    "    model = OrthogonalMatchingPursuit()\n",
    "    model = GridSearchCV(model,  param_grid if include_params else {}, cv=3)\n",
    "    model.fit(trainX, trainY)\n",
    "\n",
    "    # Get the best model from the GridSearchCV object\n",
    "    best_model_hour = model.best_estimator_\n",
    "    predicted_results_hour = best_model_hour.predict(testX)\n",
    "    return predicted_results_hour\n",
    "def ard_regression(trainX, trainY, testX):\n",
    "    param_grid = {\n",
    "        'alpha_1': [1e-6, 1e-5, 1e-4, 1e-3],\n",
    "        'alpha_2': [1e-6, 1e-5, 1e-4, 1e-3],\n",
    "        'lambda_1': [1e-6, 1e-5, 1e-4, 1e-3],\n",
    "        'lambda_2': [1e-6, 1e-5, 1e-4, 1e-3],\n",
    "        'fit_intercept': [True, False],\n",
    "        'tol': [1e-5, 1e-4, 1e-3]\n",
    "    }\n",
    "    model = ARDRegression()\n",
    "    model = GridSearchCV(model,  param_grid if include_params else {}, cv=3)\n",
    "    model.fit(trainX, trainY)\n",
    "\n",
    "    # Get the best model from the GridSearchCV object\n",
    "    best_model_hour = model.best_estimator_\n",
    "    predicted_results_hour = best_model_hour.predict(testX)\n",
    "    return predicted_results_hour\n",
    "def logistic_regression(trainX, trainY, testX):\n",
    "    param_grid = {\n",
    "        'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
    "        'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "        'fit_intercept': [True, False],\n",
    "        'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "        'max_iter': [50, 100, 200, 500],\n",
    "        'tol': [1e-5, 1e-4, 1e-3]\n",
    "    }\n",
    "    model = LogisticRegression()\n",
    "\n",
    "    model = GridSearchCV(\n",
    "        model,  param_grid if include_params else {}, cv=KFold(n_splits=2))\n",
    "    model.fit(trainX, trainY)\n",
    "\n",
    "    # Get the best model from the GridSearchCV object\n",
    "    best_model_hour = model.best_estimator_\n",
    "    predicted_results_hour = best_model_hour.predict(testX)\n",
    "    return predicted_results_hour\n",
    "def poisson_regressor(trainX, trainY, testX):\n",
    "    param_grid = {\n",
    "        'alpha': [0.0, 0.001, 0.01, 0.1, 1, 10],\n",
    "        'fit_intercept': [True, False],\n",
    "        'max_iter': [50, 100, 200, 500],\n",
    "        'tol': [1e-5, 1e-4, 1e-3],\n",
    "        'warm_start': [True, False]\n",
    "    }\n",
    "    model = PoissonRegressor()\n",
    "\n",
    "    model = GridSearchCV(\n",
    "        model,  param_grid if include_params else {}, cv=2)\n",
    "    model.fit(trainX, trainY)\n",
    "\n",
    "    # Get the best model from the GridSearchCV object\n",
    "    best_model_hour = model.best_estimator_\n",
    "    predicted_results_hour = best_model_hour.predict(testX)\n",
    "    return predicted_results_hour\n",
    "def gamma_regressor(trainX, trainY, testX):\n",
    "    param_grid = {\n",
    "        'alpha': [0.0, 0.001, 0.01, 0.1, 1, 10],\n",
    "        'fit_intercept': [True, False],\n",
    "        'max_iter': [50, 100, 200, 500],\n",
    "        'tol': [1e-5, 1e-4, 1e-3],\n",
    "        'warm_start': [True, False]\n",
    "    }\n",
    "    model = GammaRegressor()\n",
    "\n",
    "    model = GridSearchCV(\n",
    "        model,  param_grid if include_params else {}, cv=2)\n",
    "    model.fit(trainX, trainY)\n",
    "\n",
    "    # Get the best model from the GridSearchCV object\n",
    "    best_model_hour = model.best_estimator_\n",
    "    predicted_results_hour = best_model_hour.predict(testX)\n",
    "    return predicted_results_hour\n",
    "def tweedie_regressor(trainX, trainY, testX):\n",
    "    param_grid = {\n",
    "        'alpha': [0.0, 0.001, 0.01, 0.1, 1, 10],\n",
    "        'power': [0, 1, 1.5, 2, 3],\n",
    "        'fit_intercept': [True, False],\n",
    "        'max_iter': [50, 100, 200, 500],\n",
    "        'tol': [1e-5, 1e-4, 1e-3],\n",
    "        'warm_start': [True, False]\n",
    "    }\n",
    "    model = TweedieRegressor()\n",
    "\n",
    "    model = GridSearchCV(\n",
    "        model,  param_grid if include_params else {}, cv=2)\n",
    "    model.fit(trainX, trainY)\n",
    "\n",
    "    # Get the best model from the GridSearchCV object\n",
    "    best_model_hour = model.best_estimator_\n",
    "    predicted_results_hour = best_model_hour.predict(testX)\n",
    "    return predicted_results_hour\n",
    "\n",
    "    param_grid = {\n",
    "        'alpha': [0.0, 0.001, 0.01, 0.1, 1, 10],\n",
    "        'power': [0, 1, 1.5, 2, 3],\n",
    "        'fit_intercept': [True, False],\n",
    "        'max_iter': [50, 100, 200, 500],\n",
    "        'tol': [1e-5, 1e-4, 1e-3],\n",
    "        'warm_start': [True, False]\n",
    "    }\n",
    "    model = PassiveAggressiveRegressor()\n",
    "\n",
    "    model = GridSearchCV(\n",
    "        model,  param_grid if include_params else {}, cv=2)\n",
    "    model.fit(trainX, trainY)\n",
    "\n",
    "    # Get the best model from the GridSearchCV object\n",
    "    best_model_hour = model.best_estimator_\n",
    "    predicted_results_hour = best_model_hour.predict(testX)\n",
    "    return predicted_results_hour\n",
    "def passive_aggressive_regressor(trainX, trainY, testX):\n",
    "    param_grid = {\n",
    "        'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "        'fit_intercept': [True, False],\n",
    "        'max_iter': [50, 100, 200, 500],\n",
    "        'tol': [1e-5, 1e-4, 1e-3],\n",
    "        'early_stopping': [True, False],\n",
    "        'validation_fraction': [0.1, 0.2, 0.3],\n",
    "        'n_iter_no_change': [5, 10, 15],\n",
    "        'shuffle': [True, False],\n",
    "        'warm_start': [True, False]\n",
    "    }\n",
    "    model = PassiveAggressiveRegressor()\n",
    "\n",
    "    model = GridSearchCV(\n",
    "        model,  param_grid if include_params else {}, cv=2)\n",
    "    model.fit(trainX, trainY)\n",
    "\n",
    "    # Get the best model from the GridSearchCV object\n",
    "    best_model_hour = model.best_estimator_\n",
    "    predicted_results_hour = best_model_hour.predict(testX)\n",
    "    return predicted_results_hour\n",
    "def ransac_regressor(trainX, trainY, testX):\n",
    "    param_grid = {\n",
    "        'min_samples': [0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "        'residual_threshold': [1, 5, 10, 20],\n",
    "        'max_trials': [100, 500, 1000],\n",
    "        'stop_n_inliers': [50, 100, 200],\n",
    "        'stop_score': [0.9, 0.95, 0.99],\n",
    "        'stop_probability': [0.9, 0.95, 0.99],\n",
    "        'loss': ['squared_error', 'absolute_error']\n",
    "    }\n",
    "    model = RANSACRegressor()\n",
    "    model = GridSearchCV(\n",
    "        model,  param_grid if include_params else {}, cv=2)\n",
    "    model.fit(trainX, trainY)\n",
    "\n",
    "    # Get the best model from the GridSearchCV object\n",
    "    best_model_hour = model.best_estimator_\n",
    "    predicted_results_hour = best_model_hour.predict(testX)\n",
    "    return predicted_results_hour\n",
    "def theil_sen_regressor(trainX, trainY, testX):\n",
    "    param_grid = {\n",
    "        'fit_intercept': [True, False],\n",
    "        'copy_X': [True, False],\n",
    "        'max_subpopulation': [1e4, 1e5, 1e6],\n",
    "        'n_subsamples': [None, 50, 100, 200],\n",
    "        'max_iter': [50, 100, 200, 500],\n",
    "        'tol': [1e-5, 1e-4, 1e-3],\n",
    "        'random_state': [None, 42]\n",
    "    }\n",
    "    model = TheilSenRegressor()\n",
    "    model = GridSearchCV(\n",
    "        model,  param_grid if include_params else {}, cv=2)\n",
    "    model.fit(trainX, trainY)\n",
    "\n",
    "    # Get the best model from the GridSearchCV object\n",
    "    best_model_hour = model.best_estimator_\n",
    "    predicted_results_hour = best_model_hour.predict(testX)\n",
    "    return predicted_results_hour\n",
    "def huber_regressor(trainX, trainY, testX):\n",
    "    param_grid = {\n",
    "        'epsilon': [1.0, 1.5, 2.0],\n",
    "        'fit_intercept': [True, False],\n",
    "        'alpha': [0.0001, 0.001, 0.01, 0.1],\n",
    "        'max_iter': [50, 100, 200, 500],\n",
    "        'tol': [1e-5, 1e-4, 1e-3],\n",
    "        'warm_start': [True, False]\n",
    "    }\n",
    "    model = HuberRegressor()\n",
    "    model = GridSearchCV(\n",
    "        model,  param_grid if include_params else {}, cv=2)\n",
    "    model.fit(trainX, trainY)\n",
    "\n",
    "    # Get the best model from the GridSearchCV object\n",
    "    best_model_hour = model.best_estimator_\n",
    "    predicted_results_hour = best_model_hour.predict(testX)\n",
    "    return predicted_results_hour\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START : --------------------hourly-------------------- \n",
      "\n",
      "\n",
      "Train-test set 1 : ----------------------------------------------------------------------\n",
      " (mse: 777,335.08)\t (mae: 739.01)\t (rmse: 881.67)\t (mape: 1.3)\t (r2: -1.66)\t: HuberRegressor\n",
      "\n",
      "\n",
      "\n",
      "Train-test set 2 : ----------------------------------------------------------------------\n",
      " (mse: 305,545.86)\t (mae: 391.86)\t (rmse: 552.76)\t (mape: 0.59)\t (r2: -0.72)\t: HuberRegressor\n",
      "\n",
      "\n",
      "\n",
      "BEST PERFORMANCE hourly\n",
      "\n",
      "+ MSE : HuberRegressor = 305545.8608488768\n",
      "+ MAE : HuberRegressor = 391.86394811825016\n",
      "+ RMSE : HuberRegressor = 552.76202913087\n",
      "+ MAPE : HuberRegressor = 0.5947573938575146\n",
      "+ R2 : HuberRegressor = -1.6558807651893552\n",
      "\n",
      "\n",
      "\n",
      "END : --------------------hourly--------------------\n"
     ]
    }
   ],
   "source": [
    "include_params = True\n",
    "\n",
    "\n",
    "def huber_regressor(trainX, trainY, testX):\n",
    "    param_grid = {\n",
    "        'epsilon': [1.0, 1.5, 2.0],\n",
    "        'fit_intercept': [True, False],\n",
    "        'alpha': [0.0001, 0.001, 0.01, 0.1],\n",
    "        'max_iter': [50, 100, 200, 500],\n",
    "        'tol': [1e-5, 1e-4, 1e-3],\n",
    "        'warm_start': [True, False]\n",
    "    }\n",
    "    model = HuberRegressor()\n",
    "    model = GridSearchCV(\n",
    "        model,  param_grid if include_params else {}, cv=2)\n",
    "    model.fit(trainX, trainY)\n",
    "\n",
    "    # Get the best model from the GridSearchCV object\n",
    "    best_model_hour = model.best_estimator_\n",
    "    predicted_results_hour = best_model_hour.predict(testX)\n",
    "    return predicted_results_hour\n",
    "\n",
    "def result_mode(dataset, name):\n",
    "  # Initial \n",
    "  print(f\"START : {'-'*20}{name}{'-'*20} \\n\\n\")\n",
    "  index = ['mse', 'mae', 'rmse', 'mape', 'r2']\n",
    "  best_value = {i: float('inf') for i in index}\n",
    "  best_model = {i: '' for i in index}\n",
    "\n",
    "  for i, (X_train, y_train, X_test, y_test) in enumerate(dataset):\n",
    "      print(f\"Train-test set {i + 1} : {'-'*70}\")\n",
    "      columns = []\n",
    "      data = []\n",
    "      data_dict  = []\n",
    "      # ============================================================================================================\n",
    "\n",
    "      # model_name = 'LinearRegression'\n",
    "      # regression_pred = linear_regression(X_train, y_train, X_test)\n",
    "      # regression_dict, regression_values = timeseries_evaluation_metrics_func(y_test, regression_pred)\n",
    "      # columns.append(model_name)\n",
    "      # data.append(regression_values)\n",
    "      # data_dict.append(regression_dict)\n",
    "      # print_values_metrics(model_name, regression_dict)\n",
    "\n",
    "      # model_name = 'Ridge'\n",
    "      # regression_pred = ridge(X_train, y_train, X_test)\n",
    "      # regression_dict, regression_values = timeseries_evaluation_metrics_func(\n",
    "      #     y_test, regression_pred)\n",
    "      # columns.append(model_name)\n",
    "      # data.append(regression_values)\n",
    "      # data_dict.append(regression_dict)\n",
    "      # print_values_metrics(model_name, regression_dict)\n",
    "\n",
    "      # model_name = 'Lasso'\n",
    "      # regression_pred = lasso(X_train, y_train, X_test)\n",
    "      # regression_dict, regression_values = timeseries_evaluation_metrics_func(\n",
    "      #     y_test, regression_pred)\n",
    "      # columns.append(model_name)\n",
    "      # data.append(regression_values)\n",
    "      # data_dict.append(regression_dict)\n",
    "      # print_values_metrics(model_name, regression_dict)\n",
    "\n",
    "      # model_name = 'BayesianRidge'\n",
    "      # regression_pred = bayesian_ridge(X_train, y_train, X_test)\n",
    "      # regression_dict, regression_values = timeseries_evaluation_metrics_func(\n",
    "      #     y_test, regression_pred)\n",
    "      # columns.append(model_name)\n",
    "      # data.append(regression_values)\n",
    "      # data_dict.append(regression_dict)\n",
    "      # print_values_metrics(model_name, regression_dict)\n",
    "\n",
    "      # model_name = 'OrthogonalMatchingPursuit'\n",
    "      # regression_pred = orthogonal_matching_pursuit(X_train, y_train, X_test)\n",
    "      # regression_dict, regression_values = timeseries_evaluation_metrics_func(\n",
    "      #     y_test, regression_pred)\n",
    "      # columns.append(model_name)\n",
    "      # data.append(regression_values)\n",
    "      # data_dict.append(regression_dict)\n",
    "      # print_values_metrics(model_name, regression_dict)\n",
    "\n",
    "      # model_name = 'ARDRegression'\n",
    "      # regression_pred = ard_regression(X_train, y_train, X_test)\n",
    "      # regression_dict, regression_values = timeseries_evaluation_metrics_func(\n",
    "      #     y_test, regression_pred)\n",
    "      # columns.append(model_name)\n",
    "      # data.append(regression_values)\n",
    "      # data_dict.append(regression_dict)\n",
    "      # print_values_metrics(model_name, regression_dict)\n",
    "\n",
    "      # model_name = 'LogisticRegression'\n",
    "      # regression_pred = logistic_regression(X_train, y_train, X_test)\n",
    "      # regression_dict, regression_values = timeseries_evaluation_metrics_func(\n",
    "      #     y_test, regression_pred)\n",
    "      # columns.append(model_name)\n",
    "      # data.append(regression_values)\n",
    "      # data_dict.append(regression_dict)\n",
    "      # print_values_metrics(model_name, regression_dict)\n",
    "\n",
    "      # model_name = 'GammaRegressor'\n",
    "      # regression_pred = gamma_regressor(X_train, y_train, X_test)\n",
    "      # regression_dict, regression_values = timeseries_evaluation_metrics_func(\n",
    "      #     y_test, regression_pred)\n",
    "      # columns.append(model_name)\n",
    "      # data.append(regression_values)\n",
    "      # data_dict.append(regression_dict)\n",
    "      # print_values_metrics(model_name, regression_dict)\n",
    "\n",
    "      # model_name = 'TweedieRegressor'\n",
    "      # regression_pred = tweedie_regressor(X_train, y_train, X_test)\n",
    "      # regression_dict, regression_values = timeseries_evaluation_metrics_func(\n",
    "      #     y_test, regression_pred)\n",
    "      # columns.append(model_name)\n",
    "      # data.append(regression_values)\n",
    "      # data_dict.append(regression_dict)\n",
    "      # print_values_metrics(model_name, regression_dict)\n",
    "\n",
    "      # model_name = 'PassiveAggressiveRegressor'\n",
    "      # regression_pred = passive_aggressive_regressor(X_train, y_train, X_test)\n",
    "      # regression_dict, regression_values = timeseries_evaluation_metrics_func(\n",
    "      #     y_test, regression_pred)\n",
    "      # columns.append(model_name)\n",
    "      # data.append(regression_values)\n",
    "      # data_dict.append(regression_dict)\n",
    "      # print_values_metrics(model_name, regression_dict)\n",
    "\n",
    "      # model_name = 'RANSACRegressor'\n",
    "      # regression_pred = ransac_regressor(X_train, y_train, X_test)\n",
    "      # regression_dict, regression_values = timeseries_evaluation_metrics_func(\n",
    "      #     y_test, regression_pred)\n",
    "      # columns.append(model_name)\n",
    "      # data.append(regression_values)\n",
    "      # data_dict.append(regression_dict)\n",
    "      # print_values_metrics(model_name, regression_dict)\n",
    "      \n",
    "      # model_name = 'TheilSenRegressor'\n",
    "      # regression_pred = theil_sen_regressor(X_train, y_train, X_test)\n",
    "      # regression_dict, regression_values = timeseries_evaluation_metrics_func(\n",
    "      #     y_test, regression_pred)\n",
    "      # columns.append(model_name)\n",
    "      # data.append(regression_values)\n",
    "      # data_dict.append(regression_dict)\n",
    "      # print_values_metrics(model_name, regression_dict)\n",
    "\n",
    "      # model_name = 'HuberRegressor'\n",
    "      # regression_pred = huber_regressor(X_train, y_train, X_test)\n",
    "      # regression_dict, regression_values = timeseries_evaluation_metrics_func(\n",
    "      #     y_test, regression_pred)\n",
    "      # columns.append(model_name)\n",
    "      # data.append(regression_values)\n",
    "      # data_dict.append(regression_dict)\n",
    "      # print_values_metrics(model_name, regression_dict)\n",
    "\n",
    "      # ============================================================================================================\n",
    "      # Finding best \n",
    "      for model_name, performance in zip(columns, data_dict):\n",
    "        for perf in performance:\n",
    "          if performance[perf] < best_value[perf]:\n",
    "            best_value[perf] = performance[perf] \n",
    "            best_model[perf] = model_name\n",
    "\n",
    "      # Save from dataframe\n",
    "      save_stats_df = pd.DataFrame(data=dataframe_splitter(data, len(index)), index=index, columns=columns)\n",
    "      save_stats_df.to_csv(f\"{name}-Train-test-set_{i + 1}.csv\")\n",
    "      print(\"\\n\\n\")\n",
    "\n",
    "\n",
    "  # Print Best model with best value \n",
    "  print(f\"BEST PERFORMANCE {name}\\n\")\n",
    "  print('\\n'.join([f'+ {i.upper()} : {best_model[i]} = {best_value[i]}' for i in index]))\n",
    "  print(\"\\n\\n\")\n",
    "  print(f\"END : {'-'*20}{name}{'-'*20}\")\n",
    "\n",
    "result_mode(train_test_hour, 'hourly')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
